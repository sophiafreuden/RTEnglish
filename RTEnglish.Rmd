---
title: "RTEnglish"
author: "Sophia Freuden"
date: "1/7/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
library(tm)
library(SentimentAnalysis)
library(syuzhet)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(RCurl)
library(textclean)
library(lubridate)
library(gt)
library(tidyverse)
```

```{r}
col_types = cols(
  date = col_character(),
  title = col_character(),
  content = col_character(),
  URL = col_character()
)
```

```{r}
# Be sure to use correct data files for your chosen individual. Leave others commented out.

# clinton:
# data1 <- read_csv("clinton-civil-society/clinton-civil-society.csv", col_types = col_types)
# data2 <- read_csv("clinton-maidan/clinton-maidan.csv", col_types = col_types)
# data3 <- read_csv("clinton-orange-revolution/clinton-orange-revolution.csv",
#                  col_types = col_types)

# mcfaul:
# data4 <- read_csv("mcfaul/mcfaul.csv", col_types = col_types)

# Skipping over Orange Revolution in Final Version
# dataX <- read_csv("orange-revolution/orange-revolution.csv", col_types = col_types)

# soros:
data5 <- read_csv("soros-civil-society/soros-civil-society.csv", col_types = col_types)
data6 <- read_csv("soros-democratic-party/soros-democratic-party.csv", col_types = col_types)
data7 <- read_csv("soros-elections/soros-elections.csv", col_types = col_types)
data8 <- read_csv("soros-eu/soros-eu.csv", col_types = col_types)
data9 <- read_csv("soros-globalism/soros-globalism.csv", col_types = col_types)
data10 <- read_csv("soros-nato/soros-nato.csv", col_types = col_types)
data11<- read_csv("soros-open-society/soros-open-society.csv", col_types = col_types)
data12 <- read_csv("soros-russia/soros-russia.csv", col_types = col_types)
data13 <- read_csv("stop-soros/stop-soros.csv", col_types = col_types)
```

```{r}
# soros

data56 <- bind_rows(data5, data6)
data567 <- bind_rows(data56, data7)
data5678 <- bind_rows(data567, data8)
data56789 <- bind_rows(data5678, data9)
data5678910 <- bind_rows(data56789, data10)
data567891011 <- bind_rows(data5678910, data11)
data56789101112 <- bind_rows(data567891011, data12)
all_soros <- bind_rows(data56789101112, data13)

data <- unique(all_soros)
```

```{r}
data <- data %>%
  mutate(date = dmy(date))

# You might get parsing errors. View the data to make sure the dates are okay, otherwise you can ignore them.

# view(data)

# Some of the cells in the content column may appear empty in view(). Print one row in console to check. I suspect they are just too big to appear in view(), but are otherwise present.
```

```{r}
Encoding(data$content) <- "latin1"

data$content <- replace_non_ascii(data$content)
```

```{r}
corpus <- SimpleCorpus(VectorSource(data$content))
# view(corpus)
```

```{r}
corpus <- tm_map(corpus, stripWhitespace)

corpus <- tm_map(corpus, content_transformer(tolower))

corpus <- tm_map(corpus, removeNumbers)

corpus <- tm_map(corpus, removePunctuation)

corpus <- tm_map(corpus, removeWords, stopwords("english"))
```

```{r}
nonstem.corpus <- corpus
corpus <- tm_map(corpus, stemDocument)
```

```{r}
DTM <- DocumentTermMatrix(corpus)
# view(DTM)
# inspect(DTM)
```

```{r}
nDTM <- DocumentTermMatrix(nonstem.corpus)
# view(nDTM)
```

```{r}
sums <- as.data.frame(colSums(as.matrix(nDTM)))
sums <- rownames_to_column(sums) 
colnames(sums) <- c("term", "count")
sums <- arrange(sums, desc(count))
head <- sums[1:75,]

sums2 <- as.data.frame(as.matrix(nDTM))
sums2d <- as.data.frame(as.matrix(DTM))
```

```{r}
sums2$ArtDate <- data$date
sums2d$ArtDate <- data$date
```

```{r}
# Use this to find outliers and filter them out. You can replot them by replacing
# sums2/sums2d in the code chunk below and changing the caption to "Outliers
# removed."

# I keep this commented out when I'm not actively using it.

# temp <- sums2 %>% select(c(ArtDate, ngos))
# temp2 <- temp %>% filter(ngos <= 18)
# view(temp)
```

```{r}
# Summed per date. Change between sums2 and sums2d (stemmed) as needed.

# CHANGE BELOW:
# term in sum() below and
# 'Term' and 'RT Seach Term' to whatever term/search term your data is based on.

sums2 %>%
  # The group_by and summarise below sum the articles by date. Alt version c'd out below.
  group_by(ArtDate) %>% 
  summarise(Frequency = sum(ngos)) %>%
  ggplot(aes(x = ArtDate, y = Frequency)) +
  geom_point() +
  # geom_smooth(method = 'loess') +
  labs(
    title = "Term Frequency Per Article Over Time",
    subtitle = "Term: 'ngos', RT Search Term: N/A, 'Soros' Terms",
    x = "Date",
    y = "Frequency"
    # Comment/uncomment caption below as needed. Add/delete comma in line above, too.
    # caption = "Stemmed"
  ) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggsave("all-soros/ngos2.png", width = 10)
```

```{r}
# Non-summed per date.
# Folloew "Change Below" instructions above, but sum() term is y below.

# sums2 %>%
#   ggplot(aes(x = ArtDate, y = soros)) +
#   geom_point() +
#   geom_smooth(method = 'loess') +
#   labs(
#     title = "Term Frequency Per Article Time",
#     subtitle = "Term: 'soros', RT Search Term: 'soros russia'",
#     x = "Date",
#     y = "Frequency"
#   ) +
#   scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#   ggsave("plot2.png", width = 10)
```

```{r}
wordcloud(words = head$term, freq = head$count, min.freq = 1000,
  max.words=100, random.order=FALSE, rot.per=0.35, 
  colors=brewer.pal(8, "Dark2"))

# This must be saved manually (right click the image when it appears.)
```

```{r}
# The word cloud above uses the non-stemmed documents. The one below used the stemmed
# documents. For word clouds specifically, it may be better to use non-stemmed documents.
```

```{r}
sums3 <- as.data.frame(colSums(as.matrix(DTM)))
sums3 <- rownames_to_column(sums3) 
colnames(sums3) <- c("term", "count")
sums3 <- arrange(sums3, desc(count))
head3 <- sums3[1:75,]
```

```{r}
wordcloud(words = head3$term, freq = head3$count, min.freq = 75,
  max.words=100, random.order=FALSE, rot.per=0.35, 
  colors=brewer.pal(8, "Dark2"))
```

```{r}
sent <- analyzeSentiment(DTM, language = "english")
# view(sent)

sent <- sent[,1:4]

sent <- as.data.frame(sent)

# view(sent)

sum1 <- tibble(summary(sent$SentimentGI))

final <- bind_cols(data, sent)

# head(final)
```

```{r}
sum2 <- as.data.frame(t(sum1))

# CHANGE BELOW 'RT Seach Term' to whatever search term your data is based on.
sum2 %>%
  gt() %>%
  tab_header(
    title = "Sentiment Polarization Summary",
    subtitle = "RT Search Term: N/A, 'Soros' Terms"
    )  %>% 
  # #tab_source_note(
  #   source_note = "RT Search Term was entered with quotation marks for accuracy."
  #   ) %>% 
  cols_label(
    V1 = "Min.",
    V2 = "1st Qu.",
    V3 = "Median",
    V4 = "Mean",
    V5 = "3rd Qu.",
    V6 = "Max."
    ) %>% 
  gtsave("all-soros/table1.png", zoom = 2.5, expand = 10)
```

```{r}
sent2 <- get_nrc_sentiment(data$content, language = "english")

sent3 <- as.data.frame(colSums(sent2))

sent3 <- rownames_to_column(sent3)

colnames(sent3) <- c("emotion", "count")
```

```{r}
ggplot(sent3, aes(x = emotion, y = count, fill = emotion)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  theme(legend.position="none", panel.grid.major = element_blank()) +
  labs(title = "Emotion Analysis",
       x = "Emotion",
       y = "Total Count",
       subtitle = "RT Search Term: N/A, 'Soros' Terms"
       # caption = "RT Search Term was entered with quotation marks for accuracy."
       ) +
  scale_fill_brewer(palette="Paired") +
  ggsave("all-soros/emo1.png", width = 10)
```



